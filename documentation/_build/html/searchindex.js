Search.setIndex({"docnames": ["explainableRL", "explainableRL.agents", "explainableRL.data_handler", "explainableRL.environments", "explainableRL.evaluation", "explainableRL.explainability", "explainableRL.foundation", "explainableRL.performance", "index", "modules", "tests", "tests.test_agents", "tests.test_data_handler", "tests.test_environments", "tests.test_explainability", "tests.test_foundation"], "filenames": ["explainableRL.rst", "explainableRL.agents.rst", "explainableRL.data_handler.rst", "explainableRL.environments.rst", "explainableRL.evaluation.rst", "explainableRL.explainability.rst", "explainableRL.foundation.rst", "explainableRL.performance.rst", "index.rst", "modules.rst", "tests.rst", "tests.test_agents.rst", "tests.test_data_handler.rst", "tests.test_environments.rst", "tests.test_explainability.rst", "tests.test_foundation.rst"], "titles": ["explainableRL package", "explainableRL.agents package", "explainableRL.data_handler package", "explainableRL.environments package", "explainableRL.evaluation package", "explainableRL.explainability package", "explainableRL.foundation package", "explainableRL.performance package", "Welcome to Explainable RL\u2019s documentation!", "explainable-RL", "tests package", "tests.test_agents package", "tests.test_data_handler package", "tests.test_environments package", "tests.test_explainability package", "tests.test_foundation package"], "terms": {"main": 7, "modul": [8, 9], "src": 7, "packag": [8, 9], "test": [2, 4, 6, 7, 8, 9], "index": [3, 8], "search": 8, "page": 8, "policy_devi": [], "sourc": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15], "run_al": [], "hyperparam_dict": [2, 6], "verbos": [1, 3, 6, 7], "true": [2, 3, 5, 6], "show_plot": [], "subpackag": 9, "agent": [0, 3, 4, 5, 9, 15], "submodul": [0, 9], "double_q_learn": [0, 9], "q_learner": [0, 9], "sarsa": [0, 6, 9], "sarsa_lambda": [0, 9], "td": [0, 9, 11], "content": 9, "data_handl": [0, 9], "environ": [0, 1, 9], "strategic_pricing_predict": [0, 9], "strategic_pricing_suggest": [0, 9], "pdp": [0, 9, 14], "foundat": [0, 9], "engin": [0, 2, 4, 5, 9, 14, 15], "util": [0, 9, 15], "perform": [0, 1, 9], "performance_evalu": [0, 9], "test_ag": [9, 10], "test_double_q_learn": [9, 10], "test_q_learn": [9, 10], "test_sarsa": [9, 10], "test_sarsa_lambda": [9, 10], "test_td": [9, 10], "test_data_handl": [9, 10], "test_environ": [9, 10], "test_strategic_pricing_predict": [9, 10], "test_strategic_pricing_suggest": [9, 10], "test_explain": [9, 10], "test_pdp": [9, 10], "test_shap_valu": [9, 10], "test_found": [9, 10], "test_engin": [9, 10], "test_util": [9, 10], "explain": 0, "class": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15], "doubleqlearn": [1, 11], "env": [1, 6, 15], "gamma": [1, 6], "fals": [1, 3, 5, 6, 7], "base": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15], "q": [1, 5, 6], "q_num_sampl": [], "_step": 1, "epsilon": [1, 6], "lr": 1, "step": [1, 3, 6, 11, 13], "paramet": [1, 2, 3, 4, 5, 6, 7], "float": [1, 4, 5, 6, 7], "greedi": [1, 6], "polici": [1, 4, 6], "learn": 1, "rate": [1, 6], "return": [1, 2, 3, 4, 5, 6, 7], "boolean": [], "indic": 6, "whether": [1, 3, 5, 6, 7], "episod": [1, 3, 6, 7], "finish": 1, "type": [1, 2, 3, 4, 5, 6, 7, 15], "done": [3, 6], "_update_q_valu": 1, "state": [1, 2, 3, 5, 6, 14], "action": [1, 2, 3, 5, 6, 14], "next_stat": 1, "reward": [1, 2, 3, 4, 6], "kwarg": 1, "updat": [1, 6], "tabl": [1, 6], "list": [1, 2, 3, 4, 5, 6, 7], "current": [1, 3, 6], "int": [1, 3, 5, 6, 7], "select": [1, 2, 6], "next": [1, 3, 6], "explor": [1, 6], "create_t": [1, 11], "initi": [1, 3, 6], "thi": [1, 3, 4, 6], "reset": [1, 3, 6, 13], "creat": [1, 3, 6], "map": 1, "bool": [1, 2, 3, 5, 6, 7], "print": [1, 3, 6, 7], "inform": [1, 3, 6], "state_to_act": 3, "qlearningag": [1, 11], "store": [1, 2, 6, 7], "us": [1, 3, 4, 6, 7], "bellman": [], "equat": [], "q_learn": [], "sarsaag": [1, 11], "sarsalambdaag": 1, "lambda_": 1, "0": [1, 6], "9": 1, "static": [1, 6], "_convert_to_str": 6, "_epsilon_greedy_polici": [1, 6], "none": [1, 2, 3, 5, 6, 11, 12, 13, 14, 15], "1": [1, 6], "get": [1, 2, 5, 6, 7], "state_str": 6, "string": 6, "_init_q_t": 6, "zero": [2, 6], "fit": [1, 6, 11], "n_episod": [], "n_step": [], "lr_decai": [], "05": [], "lr_min": [], "01": [], "epsilon_decai": [], "epsilon_min": [], "dataset": [1, 2, 3, 6, 7], "number": [1, 3, 5, 6, 7], "per": [2, 3, 5, 7], "decai": 6, "minimum": 6, "train": [1, 2, 4, 5, 6, 7], "uncertainty_informed_polici": [1, 6, 11], "use_uncertainti": [1, 6], "q_import": [1, 6], "7": [1, 6], "favour": [1, 6], "more": [1, 6], "dens": [1, 6], "popul": [1, 6], "pair": [1, 3, 5, 6], "uncertainti": [1, 6], "import": [1, 6], "valu": [1, 3, 5, 6, 7], "datahandl": [2, 3, 6, 12], "data_path": 6, "state_label": [], "action_label": [], "reward_label": [], "n_sampl": 6, "object": [1, 2, 3, 4, 5, 6, 7, 13, 14], "data": [1, 2, 3, 5, 6, 7, 15], "handler": [2, 3, 6, 15], "preprocess": 2, "need": 2, "_action_label": [], "_filter_data": 2, "filter": 2, "_fit_standard_scalar": 2, "sklearn": 2, "minmaxscal": 2, "one": [2, 4], "column": [2, 6, 7], "todo": [], "onli": 3, "_inverse_transform_col": 2, "col_nam": 2, "str": [2, 5, 6, 7], "revers": 2, "normalis": 2, "_n_sampl": [], "_normalised_col": [], "_reward_label": [], "_state_label": [], "_transform_col": 2, "get_action_label": [2, 12], "label": [2, 6, 7], "get_act": [2, 12], "split": [2, 6], "taken": 2, "specifi": 2, "pd": [2, 6], "datafram": [2, 3, 6], "get_reward": [2, 12], "get_stat": [2, 12], "load_data": 6, "delimit": [6, 7], "load": [6, 7], "from": [1, 2, 3, 6, 7], "file": [6, 7], "param": 6, "mdp_data": [], "mdp_data_test": [], "minmax_scalar": [], "normalise_dataset": 2, "cols_to_norm": 2, "centr": 2, "mean": [2, 3], "varianc": 2, "name": [2, 5, 7], "prepare_data_for_engin": [2, 12], "col_delimit": [], "cols_to_normalis": 2, "prepar": [2, 5, 7], "preprocess_data": 2, "columns_to_normalis": 2, "train_test_split": 6, "2": [6, 7], "space": [2, 3, 7], "appli": 2, "shuffl": 2, "arg": [], "which": [2, 3, 4, 6, 7], "left": 2, "empti": 2, "all": [2, 4, 6, 7], "extens": [], "aggreg": [], "over": 7, "time": [1, 7], "period": [], "reverse_norm": [2, 12], "strategicpricingpredictionmdp": [3, 13], "dh": [3, 6, 11, 12, 13, 14, 15], "bin": [3, 5, 6, 7], "mdp": [1, 3, 6], "defin": [1, 6], "instanti": [], "strateg": [3, 6], "price": [3, 6], "_action_mdp_data": [], "_average_reward": [], "_bin_stat": [], "idx": 3, "singular": 3, "The": [1, 2, 3, 6], "ar": [3, 7], "accord": 3, "each": [1, 3, 4, 5], "featur": [3, 5, 6], "dimens": [3, 5, 7], "argument": [1, 3], "can": [1, 3], "contain": [3, 4, 5, 6], "certain": 3, "e": [3, 6, 7], "g": [3, 6, 7], "_bin_state_action_spac": 3, "zip": 3, "group": 3, "datapoint": [3, 7], "np": [3, 5], "arrai": [3, 4, 5], "_create_average_reward_matrix": 3, "bins_dict": 3, "spars": 3, "matrix": [3, 6], "associ": 3, "input": [3, 7], "dictionari": [1, 2, 3, 4, 5, 6, 7], "count": [1, 3], "sum": [1, 3], "dict": [1, 2, 3, 5, 6, 7], "averag": [3, 5], "coo": 3, "_debin_st": 3, "b_state": 3, "debin": 3, "middl": [], "point": [], "de": [3, 6], "_get_counts_and_rewards_per_bin": 3, "_get_state_to_act": 3, "_join_state_act": 3, "join": 3, "togeth": 3, "rtype": [], "_make_rewards_from_data": 3, "_reward_mdp_data": [], "_state_mdp_data": [], "_transform_df_to_numpi": 3, "transform": [3, 6], "numpi": 3, "action_dim": [], "bin_stat": [3, 13], "debin_st": [3, 13], "initialise_env": [3, 6], "given": [2, 3, 5, 6], "ix": [], "num_bin": 7, "randomis": [3, 6], "state_dim": [], "take": [1, 3, 6], "flag": [3, 6], "termin": [3, 6], "tupl": [3, 6], "strategicpricingsuggestionmdp": [3, 13], "_find_next_st": 3, "lookup": 3, "exist": 3, "visit": [1, 3, 5], "_q_arrai": [], "_bin": [], "_bins_per_dim": [], "_denorm_act": [], "_denorm_st": [], "_dig_state_act": [], "_dig_state_actions_sampl": [], "_dig_state_actions_std": [], "_get_denorm_act": 5, "denorm": [5, 14], "_get_denorm_st": 5, "_get_digitized_pdp": 5, "comput": 5, "margin": 5, "effect": 5, "other": 5, "dok": [], "build": 5, "plot": [4, 5, 7], "sampl": [4, 5, 6, 7], "_minmax_scalar": [], "build_data_for_plot": 5, "plot_pdp": 5, "states_nam": [], "fig_nam": 5, "type_featur": [], "savefig": 5, "all_stat": [], "One": 5, "figur": 5, "save": [5, 6, 7], "variabl": [], "choos": [], "how": [1, 7], "unvisit": [], "super": 6, "particular": 6, "learner": [1, 6], "predict_act": [5, 6, 14], "predict": [3, 5, 6], "epislon": [], "default": [1, 6], "pure": [1, 6], "exploit": [1, 6], "recommend": 6, "predict_reward": 6, "function": [6, 7, 15], "avg": 6, "simul": 6, "real": 6, "life": 6, "scenario": 6, "agent_typ": [], "env_typ": [], "num_episod": 7, "num_step": [], "_eval_action_dim": [], "_eval_act": [], "_eval_b_st": [], "_eval_reward": [], "_eval_state_dim": [], "_eval_st": [], "_evaluate_total_agent_reward": 6, "calcul": [4, 6], "total": [1, 4, 6], "obtain": 6, "evalu": [0, 6, 7, 9], "s": 6, "scale": 6, "cumul": [4, 6], "cumreward": [], "_evaluate_total_hist_reward": 6, "histor": [1, 4, 6], "_inverse_scale_featur": [], "normal": [5, 6], "agent_cumreward": [], "build_evalu": 6, "create_ag": [6, 15], "an": [1, 5, 6, 7], "create_env": [6, 15], "create_world": [6, 15], "instanc": [3, 6], "task": [3, 6], "episode_flag": [], "evaluate_ag": [], "correspond": [], "rewards_hist": [], "actions_ag": [], "rewards_ag": [], "get_result": [], "result": 7, "sprint": [], "compar": [], "could": [], "after": 15, "converg": [], "hist_cumreward": [], "q_tabl": [], "save_paramet": [], "dure": [], "ani": 12, "Not": [], "sure": [], "call": 1, "directli": [], "alreadi": [], "remov": [], "train_ag": [6, 15], "n_eval_step": [], "10": 7, "chosen": [6, 7], "should": [1, 3, 6], "inherit": 6, "A": 6, "convert_to_list": [6, 15], "convert": 6, "convert_to_str": [6, 11, 15], "decay_param": [6, 15], "min_param": 6, "performanceevalu": 7, "do_pre_benchmark_run_configur": [], "benchmark": 7, "run": [4, 6, 7], "get_all_performance_evalu": 7, "desir": 7, "get_benchmark_perform": 7, "constant": 7, "set": [1, 3, 4, 7, 11, 12, 13, 15], "note": [3, 7], "reason": 7, "timeit": 7, "becaus": 7, "piec": 7, "code": 7, "being": 7, "profil": 7, "lengthi": 7, "whole": 7, "flow": [3, 6, 7], "design": 7, "small": 7, "snippet": 7, "them": 7, "mani": [1, 7], "get_hyperparam_dict_ds_data": [], "num_sampl": 7, "hyperparamet": [1, 2, 6, 7], "datasparq": 7, "loop": [6, 7], "digitis": 7, "equal": 7, "specif": 7, "get_performance_graph": 7, "against": 7, "vari": 7, "held": 7, "get_post_benchmark_run_result": [], "get_space_breakdown_per_funct": 7, "breakdown": 7, "complex": 7, "get_time_breakdown_per_funct": 7, "see": 7, "http": 7, "www": 7, "machinelearningplu": 7, "com": 7, "python": 7, "cprofil": 7, "your": 7, "And": 7, "stackoverflow": 7, "question": 7, "51536411": 7, "readabl": 7, "extern": 7, "get_times_and_memory_from_parameter_rang": [], "parameter_nam": 7, "x": 7, "memori": 7, "record": 7, "rang": 7, "differ": [7, 15], "plot_performance_graph": [], "x_label": 7, "graph": [4, 7], "horizont": 7, "axi": 7, "across": 7, "have": 7, "been": [1, 5, 7], "run_training_loop": [], "exampl": 7, "py": 7, "eventu": 7, "mai": 7, "user": 7, "face": 7, "testdoubleqlearn": 11, "methodnam": [11, 12, 13, 14, 15], "runtest": [11, 12, 13, 14, 15], "testtd": 11, "setup": [11, 12, 13, 14, 15], "hook": [], "method": [4, 11, 12, 13, 14, 15], "up": [11, 12, 13, 15], "fixtur": 12, "befor": [], "exercis": [], "test_fit": 11, "implement": 11, "subclass": 11, "test_step": [11, 13], "test_update_q_valu": 11, "testqlearningag": 11, "testsarsa": 11, "testsarsalambda": 11, "testcas": [11, 12, 13, 14, 15], "classmethod": [11, 13, 14, 15], "setupclass": [11, 13, 14, 15], "teardown": [11, 12, 13, 15], "deconstruct": [], "test_convert_to_str": [11, 15], "test_create_t": 11, "test_epsilon_greedy_polici": 11, "test_init_q_t": 11, "test_uncertainty_informed_polici": 11, "testdatahandl": 12, "test_filter_data": 12, "test_fit_standard_scalar": 12, "test_inverse_transform_col": 12, "test_len_get_action_label": 12, "test_len_get_act": 12, "test_len_get_reward": 12, "test_len_get_st": 12, "test_load_data": [], "test_prepare_data_for_engin": 12, "test_reverse_norm": 12, "test_transform_col": 12, "test_type_get_action_label": 12, "test_type_get_act": 12, "test_type_get_reward": 12, "test_type_get_st": 12, "teststrategicpricingpredictionmdp": 13, "test_bin_st": 13, "test_bin_state_action_spac": 13, "test_create_average_reward_matrix": 13, "test_debin_st": 13, "test_get_counts_and_rewards_per_bin": 13, "test_join_state_act": 13, "test_make_rewards_from_data": 13, "test_reset": 13, "test_transform_df_to_numpi": 13, "test_typ": [], "teststrategicpricingsuggestionmdp": 13, "testpdp": 14, "test_build_data_for_plot": [], "test_create_pdp": 14, "creation": 14, "test_get_denorm_act": 14, "test_get_denorm_st": 14, "test_get_digitized_pdp": 14, "digit": 14, "test_pdp_plot": [], "testshapvalu": 14, "shapvalu": [5, 14], "shap_valu": [0, 9, 14], "test_bin_sampl": 14, "bin_sampl": [5, 14], "test_create_shap_valu": 14, "get_denorm_act": [5, 14], "test_normalize_sampl": 14, "normalize_sampl": [5, 14], "test_predict_act": 14, "test_sample_plus_minus_sampl": 14, "sample_plus_minus_sampl": [5, 14], "test_verify_cell_avail": 14, "verify_cell_avail": [5, 14], "test_verify_outli": 14, "verify_outli": [5, 14], "test_verify_sample_length": 14, "verify_sample_length": [5, 14], "testengin": 15, "test_build_evalu": [], "test_create_ag": 15, "test_create_env": 15, "test_create_world_ag": 15, "test_evaluate_ag": [], "test_evaluate_total_agent_reward": [], "test_evaluate_total_hist_reward": [], "test_get_result": [], "test_inverse_scale_featur": [], "test_save_paramet": [], "test_train_ag": 15, "testutil": 15, "test_convert_to_list": 15, "test_decay_param": 15, "doubl": 1, "q_a": [], "q_b": [], "check": [], "actual": [], "what": [], "you": [], "re": [], "meant": [], "do": [], "two": [], "receiv": [], "keyword": 1, "statement": [1, 3, 6, 7], "lambda": 1, "fraction": [], "ha": [1, 3, 5], "binned_st": [], "respons": 6, "update_q_valu": 11, "sarsalambda": 11, "tear": [11, 12, 13, 15], "down": [11, 12, 13, 15], "epsilon_greedy_polici": 11, "init_q_t": 11, "filter_data": 12, "fit_standard_scalar": 12, "inverse_transform_col": 12, "transform_col": 12, "bin_state_action_spac": 13, "create_average_reward_matrix": 13, "get_counts_and_rewards_per_bin": 13, "join_state_act": 13, "make_rewards_from_data": 13, "transform_df_to_numpi": 13, "rhe": [], "chang": [], "add": [], "separ": [6, 7], "strategicpr": [3, 13], "If": 2, "last": 3, "element": 3, "alwai": 3, "problem": 3, "requir": 3, "singl": 3, "suggest": 3, "partial": 5, "depend": 5, "tool": [], "parent": 6, "child": 6, "invers": 6, "coeffici": 6, "teststrategicpr": 13, "test_find_next_st": 13, "find_next_st": 13, "strategic_pr": [0, 9], "__init__": [1, 2, 3, 4, 5, 6, 7], "initialis": [1, 2, 3, 4, 5, 6, 7], "discount": [1, 6], "factor": [1, 6], "path": [6, 7], "extract": [], "discret": [], "_get_bin": 6, "_get_label": 2, "label_dict": 2, "agent_hyperparam": [1, 6], "training_hyperparam": [1, 6], "pbar": [1, 6], "tqdm": [1, 6], "progress": [1, 6, 7], "bar": [1, 6], "test_dataset": [2, 6], "about": [3, 6], "program": [3, 6], "displai": [3, 6], "inverse_scale_featur": 6, "load_engin": 6, "path_nam": 6, "save_engin": 6, "split_train_test": [6, 15], "proport": [1, 6], "train_dataset": 6, "results_path": 7, "num_sample_rang": 7, "100": 7, "1000": 7, "10000": 7, "100000": 7, "num_ep_rang": 7, "num_bin_rang": 7, "5": 7, "20": 7, "30": 7, "40": 7, "50": 7, "_do_pre_benchmark_run_configur": 7, "_get_hyperparam_dict_ds_data": 7, "_get_post_benchmark_run_result": 7, "_get_times_and_memory_from_parameter_rang": 7, "_load_data": 7, "_plot_performance_graph": 7, "_run_training_loop": 7, "librari": [0, 9], "main_evalu": [], "new_env": [], "test_strategic_pr": [9, 10], "test_hyperparam": 9, "newenviron": [], "param1": [], "new": [], "made": [], "y": [], "z": [], "docstr": [], "doe": [], "shap": 5, "binned_sampl": 5, "compute_shap_valu": 5, "predicted_act": 5, "denorm_act": 5, "normalized_sampl": 5, "shap_ft": 5, "num_bins_per_shap_ft": 5, "plu": 5, "minu": 5, "s_minu": 5, "s_plu": 5, "verifi": 5, "cell": 5, "otherwis": 5, "outlier": 5, "length": 5, "correct": 5, "total_agent_reward": 6, "total_hist_reward": 6, "test_get_state_to_act": 13, "test_get_bin": 15, "get_bin": 15, "test_load_dataset": 15, "load_dataset": 15, "test_split_train_test": 15, "_get_action_scor": 1, "possible_act": 1, "q_values_weight": 1, "uncertainty_weight": 1, "score": 1, "possibl": 1, "weight": 1, "vs": 1, "amount": 1, "seen": 1, "action_scor": 1, "_get_possible_act": 1, "_get_q_value_weight": 1, "sum_possible_q": 1, "percentag": 1, "appear": 1, "state_action_count": 1, "_get_uncertainty_weight": 1, "produc": 4, "rl": 4, "_get_evaluation_result": 4, "fill": 4, "self": 4, "eval_result": 4, "relev": 4, "metric": 4, "agent_array_reward": 4, "individu": 4, "agent_cum_reward": 4, "hist_array_reward": 4, "hist_cum_reward": 4, "plot_reward_distribut": 4, "distribut": 4, "plot_training_curv": 4, "plot_shap_valu": 5, "explainablerl": [8, 9]}, "objects": {"": [[0, 0, 0, "-", "explainableRL"], [10, 0, 0, "-", "tests"]], "explainableRL": [[1, 0, 0, "-", "agents"], [2, 0, 0, "-", "data_handler"], [3, 0, 0, "-", "environments"], [4, 0, 0, "-", "evaluation"], [5, 0, 0, "-", "explainability"], [6, 0, 0, "-", "foundation"], [7, 0, 0, "-", "performance"]], "explainableRL.agents": [[1, 0, 0, "-", "double_q_learner"], [1, 0, 0, "-", "q_learner"], [1, 0, 0, "-", "sarsa"], [1, 0, 0, "-", "sarsa_lambda"], [1, 0, 0, "-", "td"]], "explainableRL.agents.double_q_learner": [[1, 1, 1, "", "DoubleQLearner"]], "explainableRL.agents.double_q_learner.DoubleQLearner": [[1, 2, 1, "", "__init__"], [1, 2, 1, "", "_step"], [1, 2, 1, "", "_update_q_values"], [1, 2, 1, "", "create_tables"]], "explainableRL.agents.q_learner": [[1, 1, 1, "", "QLearningAgent"]], "explainableRL.agents.q_learner.QLearningAgent": [[1, 2, 1, "", "__init__"], [1, 2, 1, "", "_update_q_values"]], "explainableRL.agents.sarsa": [[1, 1, 1, "", "SarsaAgent"]], "explainableRL.agents.sarsa.SarsaAgent": [[1, 2, 1, "", "__init__"], [1, 2, 1, "", "_update_q_values"]], "explainableRL.agents.sarsa_lambda": [[1, 1, 1, "", "SarsaLambdaAgent"]], "explainableRL.agents.sarsa_lambda.SarsaLambdaAgent": [[1, 2, 1, "", "__init__"], [1, 2, 1, "", "_update_q_values"]], "explainableRL.agents.td": [[1, 1, 1, "", "TD"]], "explainableRL.agents.td.TD": [[1, 2, 1, "", "__init__"], [1, 2, 1, "", "_epsilon_greedy_policy"], [1, 2, 1, "", "_get_action_scores"], [1, 2, 1, "", "_get_possible_actions"], [1, 2, 1, "", "_get_q_value_weights"], [1, 2, 1, "", "_get_uncertainty_weights"], [1, 2, 1, "", "_step"], [1, 2, 1, "", "_update_q_values"], [1, 2, 1, "", "create_tables"], [1, 2, 1, "", "fit"], [1, 2, 1, "", "uncertainty_informed_policy"]], "explainableRL.data_handler": [[2, 0, 0, "-", "data_handler"]], "explainableRL.data_handler.data_handler": [[2, 1, 1, "", "DataHandler"]], "explainableRL.data_handler.data_handler.DataHandler": [[2, 2, 1, "", "__init__"], [2, 2, 1, "", "_filter_data"], [2, 2, 1, "", "_fit_standard_scalars"], [2, 2, 1, "", "_get_labels"], [2, 2, 1, "", "_inverse_transform_col"], [2, 2, 1, "", "_transform_col"], [2, 2, 1, "", "get_action_labels"], [2, 2, 1, "", "get_actions"], [2, 2, 1, "", "get_rewards"], [2, 2, 1, "", "get_states"], [2, 2, 1, "", "normalise_dataset"], [2, 2, 1, "", "prepare_data_for_engine"], [2, 2, 1, "", "preprocess_data"], [2, 2, 1, "", "reverse_norm"]], "explainableRL.environments": [[3, 0, 0, "-", "strategic_pricing"], [3, 0, 0, "-", "strategic_pricing_prediction"], [3, 0, 0, "-", "strategic_pricing_suggestion"]], "explainableRL.environments.strategic_pricing": [[3, 1, 1, "", "StrategicPricing"]], "explainableRL.environments.strategic_pricing.StrategicPricing": [[3, 2, 1, "", "__init__"], [3, 2, 1, "", "_bin_state_action_space"], [3, 2, 1, "", "_create_average_reward_matrix"], [3, 2, 1, "", "_debin_state"], [3, 2, 1, "", "_get_counts_and_rewards_per_bin"], [3, 2, 1, "", "_get_state_to_action"], [3, 2, 1, "", "_join_state_action"], [3, 2, 1, "", "_make_rewards_from_data"], [3, 2, 1, "", "_transform_df_to_numpy"], [3, 2, 1, "", "bin_state"], [3, 2, 1, "", "bin_states"], [3, 2, 1, "", "debin_states"], [3, 2, 1, "", "initialise_env"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "step"]], "explainableRL.environments.strategic_pricing_prediction": [[3, 1, 1, "", "StrategicPricingPredictionMDP"]], "explainableRL.environments.strategic_pricing_prediction.StrategicPricingPredictionMDP": [[3, 2, 1, "", "__init__"], [3, 2, 1, "", "_create_average_reward_matrix"], [3, 2, 1, "", "_get_counts_and_rewards_per_bin"], [3, 2, 1, "", "_make_rewards_from_data"], [3, 2, 1, "", "_transform_df_to_numpy"], [3, 2, 1, "", "step"]], "explainableRL.environments.strategic_pricing_suggestion": [[3, 1, 1, "", "StrategicPricingSuggestionMDP"]], "explainableRL.environments.strategic_pricing_suggestion.StrategicPricingSuggestionMDP": [[3, 2, 1, "", "__init__"], [3, 2, 1, "", "_create_average_reward_matrix"], [3, 2, 1, "", "_find_next_state"], [3, 2, 1, "", "_get_counts_and_rewards_per_bin"], [3, 2, 1, "", "_make_rewards_from_data"], [3, 2, 1, "", "_transform_df_to_numpy"], [3, 2, 1, "", "step"]], "explainableRL.evaluation": [[4, 0, 0, "-", "evaluator"]], "explainableRL.evaluation.evaluator": [[4, 1, 1, "", "Evaluator"]], "explainableRL.evaluation.evaluator.Evaluator": [[4, 2, 1, "", "__init__"], [4, 2, 1, "", "_get_evaluation_results"], [4, 2, 1, "", "agent_array_rewards"], [4, 2, 1, "", "agent_cum_rewards"], [4, 2, 1, "", "hist_array_rewards"], [4, 2, 1, "", "hist_cum_rewards"], [4, 2, 1, "", "plot_reward_distribution"], [4, 2, 1, "", "plot_training_curve"]], "explainableRL.explainability": [[5, 0, 0, "-", "pdp"], [5, 0, 0, "-", "shap_values"]], "explainableRL.explainability.pdp": [[5, 1, 1, "", "PDP"]], "explainableRL.explainability.pdp.PDP": [[5, 2, 1, "", "__init__"], [5, 2, 1, "", "_get_denorm_actions"], [5, 2, 1, "", "_get_denorm_states"], [5, 2, 1, "", "_get_digitized_pdp"], [5, 2, 1, "", "build_data_for_plots"], [5, 2, 1, "", "plot_pdp"]], "explainableRL.explainability.shap_values": [[5, 1, 1, "", "ShapValues"]], "explainableRL.explainability.shap_values.ShapValues": [[5, 2, 1, "", "__init__"], [5, 2, 1, "", "bin_sample"], [5, 2, 1, "", "compute_shap_values"], [5, 2, 1, "", "get_denorm_actions"], [5, 2, 1, "", "normalize_sample"], [5, 2, 1, "", "plot_shap_values"], [5, 2, 1, "", "predict_action"], [5, 2, 1, "", "sample_plus_minus_samples"], [5, 2, 1, "", "verify_cell_availability"], [5, 2, 1, "", "verify_outliers"], [5, 2, 1, "", "verify_sample_length"]], "explainableRL.foundation": [[6, 0, 0, "-", "agent"], [6, 0, 0, "-", "engine"], [6, 0, 0, "-", "environment"], [6, 0, 0, "-", "library"], [6, 0, 0, "-", "utils"]], "explainableRL.foundation.agent": [[6, 1, 1, "", "Agent"]], "explainableRL.foundation.agent.Agent": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "_convert_to_string"], [6, 2, 1, "", "_epsilon_greedy_policy"], [6, 2, 1, "", "_init_q_table"], [6, 2, 1, "", "fit"], [6, 2, 1, "", "predict_actions"], [6, 2, 1, "", "predict_rewards"], [6, 2, 1, "", "uncertainty_informed_policy"]], "explainableRL.foundation.engine": [[6, 1, 1, "", "Engine"]], "explainableRL.foundation.engine.Engine": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "_evaluate_total_agent_reward"], [6, 2, 1, "", "_evaluate_total_hist_reward"], [6, 2, 1, "", "_get_bins"], [6, 2, 1, "", "build_evaluation"], [6, 2, 1, "", "create_agent"], [6, 2, 1, "", "create_env"], [6, 2, 1, "", "create_world"], [6, 2, 1, "", "inverse_scale_feature"], [6, 2, 1, "", "train_agent"]], "explainableRL.foundation.environment": [[6, 1, 1, "", "MDP"]], "explainableRL.foundation.environment.MDP": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "initialise_env"], [6, 2, 1, "", "reset"], [6, 2, 1, "", "step"]], "explainableRL.foundation.utils": [[6, 3, 1, "", "convert_to_list"], [6, 3, 1, "", "convert_to_string"], [6, 3, 1, "", "decay_param"], [6, 3, 1, "", "load_data"], [6, 3, 1, "", "load_engine"], [6, 3, 1, "", "save_engine"], [6, 3, 1, "", "split_train_test"]], "explainableRL.performance": [[7, 0, 0, "-", "performance_evaluator"]], "explainableRL.performance.performance_evaluator": [[7, 1, 1, "", "PerformanceEvaluator"]], "explainableRL.performance.performance_evaluator.PerformanceEvaluator": [[7, 2, 1, "", "__init__"], [7, 2, 1, "", "_do_pre_benchmark_run_configuration"], [7, 2, 1, "", "_get_hyperparam_dict_ds_data"], [7, 2, 1, "", "_get_post_benchmark_run_results"], [7, 2, 1, "", "_get_times_and_memory_from_parameter_range"], [7, 2, 1, "", "_load_data"], [7, 2, 1, "", "_plot_performance_graph"], [7, 2, 1, "", "_run_training_loop"], [7, 2, 1, "", "get_all_performance_evaluations"], [7, 2, 1, "", "get_benchmark_performance"], [7, 2, 1, "", "get_performance_graphs"], [7, 2, 1, "", "get_space_breakdown_per_function"], [7, 2, 1, "", "get_time_breakdown_per_function"]], "tests": [[11, 0, 0, "-", "test_agents"], [12, 0, 0, "-", "test_data_handler"], [13, 0, 0, "-", "test_environments"], [14, 0, 0, "-", "test_explainability"], [15, 0, 0, "-", "test_foundation"], [10, 0, 0, "-", "test_hyperparams"]], "tests.test_agents": [[11, 0, 0, "-", "test_double_q_learner"], [11, 0, 0, "-", "test_q_learner"], [11, 0, 0, "-", "test_sarsa"], [11, 0, 0, "-", "test_sarsa_lambda"], [11, 0, 0, "-", "test_td"]], "tests.test_agents.test_double_q_learner": [[11, 1, 1, "", "TestDoubleQLearner"]], "tests.test_agents.test_double_q_learner.TestDoubleQLearner": [[11, 2, 1, "", "setUp"], [11, 2, 1, "", "test_fit"], [11, 2, 1, "", "test_step"], [11, 2, 1, "", "test_update_q_values"]], "tests.test_agents.test_q_learner": [[11, 1, 1, "", "TestQLearningAgent"]], "tests.test_agents.test_q_learner.TestQLearningAgent": [[11, 2, 1, "", "setUp"], [11, 2, 1, "", "test_fit"], [11, 2, 1, "", "test_step"], [11, 2, 1, "", "test_update_q_values"]], "tests.test_agents.test_sarsa": [[11, 1, 1, "", "TestSarsa"]], "tests.test_agents.test_sarsa.TestSarsa": [[11, 2, 1, "", "setUp"], [11, 2, 1, "", "test_fit"], [11, 2, 1, "", "test_step"], [11, 2, 1, "", "test_update_q_values"]], "tests.test_agents.test_sarsa_lambda": [[11, 1, 1, "", "TestSarsaLambda"]], "tests.test_agents.test_sarsa_lambda.TestSarsaLambda": [[11, 2, 1, "", "setUp"], [11, 2, 1, "", "test_update_q_values"]], "tests.test_agents.test_td": [[11, 1, 1, "", "TestTD"]], "tests.test_agents.test_td.TestTD": [[11, 4, 1, "", "dh"], [11, 2, 1, "", "setUp"], [11, 2, 1, "", "setUpClass"], [11, 2, 1, "", "tearDown"], [11, 2, 1, "", "test_convert_to_string"], [11, 2, 1, "", "test_create_tables"], [11, 2, 1, "", "test_epsilon_greedy_policy"], [11, 2, 1, "", "test_fit"], [11, 2, 1, "", "test_init_q_table"], [11, 2, 1, "", "test_step"], [11, 2, 1, "", "test_uncertainty_informed_policy"], [11, 2, 1, "", "test_update_q_values"]], "tests.test_data_handler": [[12, 0, 0, "-", "test_data_handler"]], "tests.test_data_handler.test_data_handler": [[12, 1, 1, "", "TestDataHandler"]], "tests.test_data_handler.test_data_handler.TestDataHandler": [[12, 4, 1, "", "dh"], [12, 2, 1, "", "setUp"], [12, 2, 1, "", "tearDown"], [12, 2, 1, "", "test_filter_data"], [12, 2, 1, "", "test_fit_standard_scalars"], [12, 2, 1, "", "test_inverse_transform_col"], [12, 2, 1, "", "test_len_get_action_labels"], [12, 2, 1, "", "test_len_get_actions"], [12, 2, 1, "", "test_len_get_rewards"], [12, 2, 1, "", "test_len_get_states"], [12, 2, 1, "", "test_prepare_data_for_engine"], [12, 2, 1, "", "test_reverse_norm"], [12, 2, 1, "", "test_transform_col"], [12, 2, 1, "", "test_type_get_action_labels"], [12, 2, 1, "", "test_type_get_actions"], [12, 2, 1, "", "test_type_get_rewards"], [12, 2, 1, "", "test_type_get_states"]], "tests.test_environments": [[13, 0, 0, "-", "test_strategic_pricing"], [13, 0, 0, "-", "test_strategic_pricing_prediction"], [13, 0, 0, "-", "test_strategic_pricing_suggestion"]], "tests.test_environments.test_strategic_pricing": [[13, 1, 1, "", "TestStrategicPricing"]], "tests.test_environments.test_strategic_pricing.TestStrategicPricing": [[13, 4, 1, "", "dh"], [13, 2, 1, "", "setUp"], [13, 2, 1, "", "setUpClass"], [13, 2, 1, "", "tearDown"], [13, 2, 1, "", "test_bin_state"], [13, 2, 1, "", "test_bin_state_action_space"], [13, 2, 1, "", "test_bin_states"], [13, 2, 1, "", "test_debin_state"], [13, 2, 1, "", "test_debin_states"], [13, 2, 1, "", "test_get_state_to_action"], [13, 2, 1, "", "test_join_state_action"], [13, 2, 1, "", "test_reset"]], "tests.test_environments.test_strategic_pricing_prediction": [[13, 1, 1, "", "TestStrategicPricingPredictionMDP"]], "tests.test_environments.test_strategic_pricing_prediction.TestStrategicPricingPredictionMDP": [[13, 2, 1, "", "setUp"], [13, 2, 1, "", "tearDown"], [13, 2, 1, "", "test_create_average_reward_matrix"], [13, 2, 1, "", "test_get_counts_and_rewards_per_bin"], [13, 2, 1, "", "test_make_rewards_from_data"], [13, 2, 1, "", "test_step"], [13, 2, 1, "", "test_transform_df_to_numpy"]], "tests.test_environments.test_strategic_pricing_suggestion": [[13, 1, 1, "", "TestStrategicPricingSuggestionMDP"]], "tests.test_environments.test_strategic_pricing_suggestion.TestStrategicPricingSuggestionMDP": [[13, 2, 1, "", "setUp"], [13, 2, 1, "", "tearDown"], [13, 2, 1, "", "test_create_average_reward_matrix"], [13, 2, 1, "", "test_find_next_state"], [13, 2, 1, "", "test_get_counts_and_rewards_per_bin"], [13, 2, 1, "", "test_make_rewards_from_data"], [13, 2, 1, "", "test_step"], [13, 2, 1, "", "test_transform_df_to_numpy"]], "tests.test_explainability": [[14, 0, 0, "-", "test_pdp"], [14, 0, 0, "-", "test_shap_values"]], "tests.test_explainability.test_pdp": [[14, 1, 1, "", "TestPDP"]], "tests.test_explainability.test_pdp.TestPDP": [[14, 4, 1, "", "dh"], [14, 4, 1, "", "engine"], [14, 4, 1, "", "pdp"], [14, 2, 1, "", "setUpClass"], [14, 2, 1, "", "test_create_pdp"], [14, 2, 1, "", "test_get_denorm_actions"], [14, 2, 1, "", "test_get_denorm_states"], [14, 2, 1, "", "test_get_digitized_pdp"]], "tests.test_explainability.test_shap_values": [[14, 1, 1, "", "TestShapValues"]], "tests.test_explainability.test_shap_values.TestShapValues": [[14, 4, 1, "", "dh"], [14, 4, 1, "", "engine"], [14, 2, 1, "", "setUpClass"], [14, 4, 1, "", "shap_values"], [14, 2, 1, "", "test_bin_sample"], [14, 2, 1, "", "test_create_shap_values"], [14, 2, 1, "", "test_get_denorm_actions"], [14, 2, 1, "", "test_normalize_sample"], [14, 2, 1, "", "test_predict_action"], [14, 2, 1, "", "test_sample_plus_minus_samples"], [14, 2, 1, "", "test_verify_cell_availability"], [14, 2, 1, "", "test_verify_outliers"], [14, 2, 1, "", "test_verify_sample_length"]], "tests.test_foundation": [[15, 0, 0, "-", "test_engine"], [15, 0, 0, "-", "test_utils"]], "tests.test_foundation.test_engine": [[15, 1, 1, "", "TestEngine"]], "tests.test_foundation.test_engine.TestEngine": [[15, 4, 1, "", "dh"], [15, 2, 1, "", "setUp"], [15, 2, 1, "", "setUpClass"], [15, 2, 1, "", "tearDown"], [15, 2, 1, "", "test_create_agent"], [15, 2, 1, "", "test_create_env"], [15, 2, 1, "", "test_create_world_agents"], [15, 2, 1, "", "test_get_bins"], [15, 2, 1, "", "test_train_agent"]], "tests.test_foundation.test_utils": [[15, 1, 1, "", "TestUtils"]], "tests.test_foundation.test_utils.TestUtils": [[15, 2, 1, "", "test_convert_to_list"], [15, 2, 1, "", "test_convert_to_string"], [15, 2, 1, "", "test_decay_param"], [15, 2, 1, "", "test_load_dataset"], [15, 2, 1, "", "test_split_train_test"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"welcom": 8, "explain": [5, 8, 9], "rl": [8, 9], "s": 8, "document": 8, "content": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "indic": 8, "tabl": 8, "main": [], "modul": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15], "src": [], "packag": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15], "subpackag": [0, 10], "agent": [1, 6], "submodul": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15], "double_q_learn": 1, "q_learner": 1, "sarsa": 1, "sarsa_lambda": 1, "td": 1, "data_handl": 2, "environ": [3, 6], "strategic_pricing_predict": 3, "strategic_pricing_suggest": 3, "pdp": 5, "foundat": 6, "engin": 6, "util": 6, "perform": 7, "performance_evalu": 7, "test": [10, 11, 12, 13, 14, 15], "test_ag": 11, "test_double_q_learn": 11, "test_q_learn": 11, "test_sarsa": 11, "test_sarsa_lambda": 11, "test_td": 11, "test_data_handl": 12, "test_environ": 13, "test_strategic_pricing_predict": 13, "test_strategic_pricing_suggest": 13, "test_explain": 14, "test_pdp": 14, "test_shap_valu": 14, "test_found": 15, "test_engin": 15, "test_util": 15, "main_evalu": [], "todo": [], "librari": 6, "paramet": [], "strategic_pr": 3, "new_env": [], "shap_valu": 5, "test_hyperparam": 10, "test_strategic_pr": 13, "explainablerl": [0, 1, 2, 3, 4, 5, 6, 7], "evalu": 4}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})